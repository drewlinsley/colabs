{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn_scraper",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewlinsley/colabs/blob/master/dnn_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bqDrZiMSVfQO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Python imports.**\n",
        "\n",
        "Let's split this into separate blocks for clarity.\n",
        "\n",
        "Here, you will import `drive` from the google colab library for connecting to [google drive](https://github.com/googlecolab/colabtools/blob/master/google/colab/drive.py) and `files` for [uploading local files](https://github.com/googlecolab/colabtools/blob/master/google/colab/files.py) (i.e. your machine) to this kernel. Finally, MediaFileUpload is a class for more efficient [uploads](https://github.com/googleapis/google-api-python-client/blob/master/googleapiclient/http.py). "
      ]
    },
    {
      "metadata": {
        "id": "SHIsvXTP9lT3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from googleapiclient.http import MediaFileUpload\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BEdxLGEYVkuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np  # Note numpy is aliased as np\n",
        "import Image\n",
        "from glob import glob  # File path collection\n",
        "import tensorflow as tf  # Note tensorflow is aliased as tf\n",
        "from matplotlib import pyplot as plt  # Library for plotting images\n",
        "\n",
        "# Keras model utilities\n",
        "from keras.models import Model  # A Keras class for constructing a deep neural network model\n",
        "from keras.models import Sequential  # A Keras class for connecting deep neural network layers \n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator  # A class for data loading during model training\n",
        "\n",
        "# Keras ResNet routines\n",
        "from keras.applications.resnet50 import ResNet50  # Import the ResNet deep neural network\n",
        "from keras.preprocessing import image  # Routines for loading image data\n",
        "from keras.applications.resnet50 import preprocess_input  # ResNet-specific routines for preprocessing images\n",
        "from keras.applications.resnet50 import decode_predictions  # ResNet-specific routines for extracting predictions\n",
        "\n",
        "# Keras layers\n",
        "from keras.layers import Dense  # A fully connected neural networld layer\n",
        "from keras.layers import Activation  # A class for point-wise nonlinearity layers\n",
        "from keras.layers import Flatten  # Reshape a tensor into a matrix\n",
        "from keras.layers import Dropout  # A regularization layer which randomly zeros neural network units during training.\n",
        "\n",
        "# Optimizers\n",
        "from keras.optimizers import Adam  # Adam optimizer https://arxiv.org/abs/1412.6980\n",
        "from keras.optimizers import SGD  # Stochastic gradient descent optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vQJXr_STYXw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will also install the google_images_download library to scrape images from websites. Later, we will pass these images through trained deep neural networks.\n",
        "\n",
        "See how we can install libraries in python using the `pip` command. This is the python package manager, and is typically called with : `pip install my_package`. Note that because we are using the jupyter/ipython interface, we have to prepend an exclamation point `!` to call pip with the command line interpreter."
      ]
    },
    {
      "metadata": {
        "id": "loerA-vW6XtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install google_images_download\n",
        "from google_images_download import google_images_download   #importing the library\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMZM6iZQbicB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Set global variables**\n",
        "\n",
        "This is not \"good programming practice\" under typical circumstances, but it is reasonable for python notebooks. So bear with me.\n",
        "\n",
        "We will set global variables (paths, etc.) and mount google drive here."
      ]
    },
    {
      "metadata": {
        "id": "1QXopZ3WcEuc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR  = \"/content/image_dataset\"\n",
        "drive.mount(\"/content/gdrive\")\n",
        "print(\"TensorFlow version: \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E0KYt-vFcgJ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Download images for your dnn.**\n",
        "\n",
        "Using the google_images_download library, scrape images related to whatever you'd like. Later, we will pass these images through a deep neural network, and evaluate what it sees.\n",
        "\n",
        "To scrape images, you will provide a python dictionary with key/value pairs that are interpreted by the library. These are (i) a comma-delimeted list of keywords of what image categories to scrape for, (ii) a per-category image limit, a boolean for whether or not to print progress, and an output directory. Feel free to change any of these.\n",
        "\n",
        "Finally, we have inserted a few print commands that will "
      ]
    },
    {
      "metadata": {
        "id": "zO6Z76AW6a60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "response = google_images_download.googleimagesdownload()   #class instantiation\n",
        "arguments = {\n",
        "  \"keywords\":\"cat,dog,bird,turtle,cheetah\",\n",
        "  \"limit\":10,\n",
        "  \"print_urls\":False,\n",
        "  \"output_directory\":TRAIN_DIR\n",
        "}\n",
        "paths = response.download(arguments)   #passing the arguments to the function\n",
        "# print(paths)   #printing absolute paths of the downloaded images\n",
        "\n",
        "categories = glob(TRAIN_DIR + '/*')\n",
        "files = []\n",
        "for cat in categories:\n",
        "  files += glob(cat + '/*.jpg')\n",
        "print files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-FoBqJrceHcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Load a pretrained ResNet dnn and process an image.**\n",
        "\n",
        "We take advantage of Keras and use its built in ResNet50 model -- a near state-of-the-art 50-layer object classification model, that has been trained on millions of images. You can load this model by initializing the ResNet50 class with the weights-argument set to `imagenet` (the name of the large-image dataset used for training).\n",
        "\n",
        "Since we aggregated paths of our scraped images in the variable `files` in the previous code block, we will begin by loading the first of those images into memory, then passing it into the model.\n",
        "\n",
        "A few comments:\n",
        "\n",
        "\n",
        "\n",
        "*   See how we have to specify `target_size` in the `load_img` method? This is because the ResNet50 model was trained on images of this size. The method will \"center crop\" images to this size after loading them.\n",
        "*   After loading the image, you convert it into an array for processing by Keras and add a singleton dimension to the first axis. The resulting image tensor will have shape `batch/height/width/channels`, or 1/224/224/3. We have to do this because the model was trained on image batches (i.e., multiple images of 224/224/3 size).\n",
        "*   Finally, the image is preprocessed by subtracting off the imagenet dataset mean value from its red/green/blue channels.  \n",
        "*   The model has a 1000-dimension output, corresponding to the probability that the image belongs to any of 1000 categories that are in the imagenet dataset. The function decode_predictions returns the category names corresponding to the models predictions.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YfALedpb_dG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights=\"imagenet\")\n",
        "\n",
        "img = image.load_img(files[0], target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = base_model.predict(x)\n",
        "top_3 = decode_predictions(preds, top=3)[0]\n",
        "print(\"Predicted: \", top_3)\n",
        "\n",
        "f = plt.figure()\n",
        "plt.imshow(img)\n",
        "plt.grid('off')\n",
        "plt.axis('off')\n",
        "plt.title(\"Ground truth: %s\\nprediction: %s\" % (files[0], top_3))\n",
        "plt.close(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNDKspRHNAMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. Initialize model and train with different sized images.**\n",
        "\n",
        "We might want to take this model and retrain it on some other task.\n",
        "\n",
        "This involves a few steps called model \"fine tuning\". We first reload the model but with the argument \"include_top\" set to False. This will load the model without its pretrained 1000-category classifier. The rest of the model uses convolutions -- sliding filters -- and by cutting off this top classifier we can map these filter responses to another task.\n",
        "\n",
        "Note how here we also change the input image size. We can do this because the model is fully convolutional until the final layer, where there is a spatially global pooling, followed by a linear readout. See below:\n",
        "\n",
        "![ResNet Architecture](https://cdn-images-1.medium.com/max/2100/1*S3TlG0XpQZSIpoDIUCQ0RQ.jpeg)\n",
        "\n",
        "Compare the 34-layer residual network to the classic \"VGG-19\" network, which uses a cascade of fully connected layers to render decisions. \n"
      ]
    },
    {
      "metadata": {
        "id": "a_QK2Xj8xUtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "HEIGHT     = 300\n",
        "WIDTH      = 300\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZoQIbT0NDmL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**5. Augmentations**\n",
        "\n",
        "CNNs are very sample inefficient: they need to be exposed to large amounts of image-level variability to reach their potential in image classification. This is because CNNs have very weak biases about natural images, relying only on convolutions that implement local-weight sharing.\n",
        "\n",
        "Image datasets can be augmented with all sorts of transformations to expose CNNs to more variability and improve performance. You can do this easily in Keras with the built-in  [ImageDataGenerator class](https://keras.io/preprocessing/image/).\n",
        "\n",
        "We set our batch size to 32 (the number of images we process at once during training), since this is a minimal size to use in a model that incorporates so-called \"batch normalization\" (like the ResNet).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w-AsSASsyxuM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AA7QSPcGNRNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** 6. \"Finetune\" a trained model for your task**\n",
        "Now we put the pieces together and create the new model for fine tuning.\n",
        "\n",
        "We build a function `build_fintune_model` that will add classifier layers (you can increase the number of these by adding numbers to the `FC_LAYERS` list) and prepare your model for finetuning. This also includes fixing the pretrained convolutional layers so that they can no longer be trained.\n",
        "\n",
        "We also include dropout, which is an effective regularizer for CNNs."
      ]
    },
    {
      "metadata": {
        "id": "XFKXKgaPz62R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = [\"cat\", \"dog\", \"bird\", \"turtle\", \"cheetah\"]\n",
        "FC_LAYERS  = [1024]\n",
        "dropout    = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFCOlxtSNYwg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**7. Save performance and plot results.**"
      ]
    },
    {
      "metadata": {
        "id": "4cdLwMG40Ei5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "NUM_EPOCHS = 1\n",
        "num_train_images = 100\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath=\"/content/gdrive/checkpoints/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n",
        "\n",
        "plot_training(history)\n",
        "\n",
        "# Plot the training and validation loss + accuracy\n",
        "def plot_training(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'r.')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # plt.figure()\n",
        "    # plt.plot(epochs, loss, 'r.')\n",
        "    # plt.plot(epochs, val_loss, 'r-')\n",
        "    # plt.title('Training and validation loss')\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig('acc_vs_epochs.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}