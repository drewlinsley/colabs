{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prep-tutorial1",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewlinsley/collabs/blob/master/dcn_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SHIsvXTP9lT3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vQJXr_STYXw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "loerA-vW6XtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install google_images_download\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zO6Z76AW6a60",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DIR  = \"/content/image_dataset\"\n",
        "\n",
        "from google_images_download import google_images_download   #importing the library\n",
        "\n",
        "response = google_images_download.googleimagesdownload()   #class instantiation\n",
        "\n",
        "arguments = {\"keywords\":\"cat,dog,bird,turtle,cheetah\",\"limit\":100,\"print_urls\":True,\"output_directory\":TRAIN_DIR}   #creating list of arguments\n",
        "paths = response.download(arguments)   #passing the arguments to the function\n",
        "print(paths)   #printing absolute paths of the downloaded images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxNgg58xy-YE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "files = os.listdir('/content/image_dataset/dog')\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfALedpb_dG3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "base_model = ResNet50(weights='imagenet')\n",
        "\n",
        "\n",
        "img = image.load_img('/content/image_dataset/dog/77. gettyimages-101904705.jpg', target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = base_model.predict(x)\n",
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_QK2Xj8xUtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "print(\"TensorFlow version: \" + tf.__version__)\n",
        "\n",
        "HEIGHT     = 300\n",
        "WIDTH      = 300\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', \n",
        "                      include_top=False, \n",
        "                      input_shape=(HEIGHT, WIDTH, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w-AsSASsyxuM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_datagen =  ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range=90,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n",
        "                                                    target_size=(HEIGHT, WIDTH), \n",
        "                                                    batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFKXKgaPz62R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    for fc in fc_layers:\n",
        "        # New FC layer, random init\n",
        "        x = Dense(fc, activation='relu')(x) \n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    # New softmax layer\n",
        "    predictions = Dense(num_classes, activation='softmax')(x) \n",
        "    \n",
        "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return finetune_model\n",
        "\n",
        "class_list = [\"pizza\", \"pasta\", \"salad\"]\n",
        "FC_LAYERS  = [1024, 1024]\n",
        "dropout    = 0.5\n",
        "\n",
        "finetune_model = build_finetune_model(base_model, \n",
        "                                      dropout=dropout, \n",
        "                                      fc_layers=FC_LAYERS, \n",
        "                                      num_classes=len(class_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4cdLwMG40Ei5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "BATCH_SIZE = 8\n",
        "num_train_images = 100\n",
        "\n",
        "adam = Adam(lr=0.00001)\n",
        "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath=\"/content/gdrive/checkpoints/\" + \"ResNet50\" + \"_model_weights.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n",
        "                                       steps_per_epoch=num_train_images // BATCH_SIZE, \n",
        "                                       shuffle=True, callbacks=callbacks_list)\n",
        "\n",
        "plot_training(history)\n",
        "\n",
        "# Plot the training and validation loss + accuracy\n",
        "def plot_training(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc, 'r.')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # plt.figure()\n",
        "    # plt.plot(epochs, loss, 'r.')\n",
        "    # plt.plot(epochs, val_loss, 'r-')\n",
        "    # plt.title('Training and validation loss')\n",
        "    plt.show()\n",
        "\n",
        "    plt.savefig('acc_vs_epochs.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}